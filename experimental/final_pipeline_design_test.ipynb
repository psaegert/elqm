{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elqm.utils import get_data_dir\n",
    "from elasticsearch import Elasticsearch\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get directories for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR:  /home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/eur_lex_data\n",
      "PREPROCESSED_DATA_DIR:  /home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = get_data_dir(\"eur_lex_data\")\n",
    "PREPROCESSED_DATA_DIR = get_data_dir(\"preprocessed\")\n",
    "\n",
    "print(\"DATA_DIR: \", DATA_DIR)\n",
    "print(\"PREPROCESSED_DATA_DIR: \", PREPROCESSED_DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initilize the LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "# Initilize the LLM model\n",
    "llm = Ollama(model=\"llama2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are several options for promts, here are several"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Answer the question based on the context: {context} \\n\\nQuestion: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    }
   ],
   "source": [
    "# Construct a prompt for the LLM model\n",
    "# There are a lot of ways to construct a prompt\n",
    "\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "\n",
    "prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")\n",
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:160: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt-llama\")\n",
    "\n",
    "prompt.messages[0].prompt.template = \"\"\"[INST]<<SYS>> You are ELQM, a helpful and specialized assistant for question-answering tasks in the domain of energy law.\n",
    "Use the following pieces of retrieved context comprised of EU regulations and other legal documents to answer the question.\n",
    "If you don't know the answer or the question cannot be answered with the context, admit that you cannot answer the question due to the limited available context.\n",
    "Furthermore, if the user asks a generic question or other situations occur, in which the context is not helpful, kindly remember the user of your purpose.\n",
    "In addition to the retrieved context, you may also consider the previous conversation history to interact with the user.\n",
    "Use three sentences maximum and keep the answer concise.<</SYS>> \n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer: [/INST]\"\"\"\n",
    "\n",
    "print(type(prompt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This thing converts a langchain message type to a string (Do we want this?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert message into a string (AT LEAST IT CLAIMS THIS BUT I SPOTTED NO DIFFERNECE)\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a chain and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "Africa is a continent located in the Eastern Hemisphere, bounded by the Mediterranean Sea to the north, the Atlantic Ocean to the west, and the Indian Ocean to the south. It is home to 54 recognized sovereign states, with a diverse range of cultures, languages, and landscapes. Africa is the second-largest continent in the world by area and is home to over 1.3 billion people, making it the second-most populous continent after Asia. The continent is known for its rich cultural heritage, including music, art, and literature, as well as its diverse wildlife and natural beauty.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\"context\": \"Africa is a continent.\", \"question\": \"What is Africa?\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the preprocessed data using langchain directoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, JSONLoader\n",
    "\n",
    "schema = {\"jq_schema\": \".\\\"File content\\\"\"}\n",
    "print(os.path.abspath(PREPROCESSED_DATA_DIR))\n",
    "\n",
    "# USE A DIR WHERE THE FINISHED PREPROCESSED DATA IS STORED\n",
    "loader = DirectoryLoader(os.path.abspath(PREPROCESSED_DATA_DIR),\n",
    "                        glob='*final.json', # [0-9]final.json\n",
    "                         show_progress=True,\n",
    "                         loader_cls=JSONLoader,\n",
    "                         loader_kwargs=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:00<00:00, 567.69it/s]\n"
     ]
    }
   ],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data storage type: <class 'list'>\n",
      "Data length: 508\n",
      "Data type: <class 'langchain_core.documents.base.Document'>\n",
      "Data content: page_content=\"\\nEUR-Lex - 31953D0030 - EN\\nAvis juridique important\\n|\\n31953D0030\\nECSC High Authority: Decision No 30-53 of 2 May 1953 on practices prohibited by Article 60 (1) of the Treaty in the common market for coal and steel  \\nOfficial Journal 006 , 04/05/1953 P. 0109 - 0110\\n Danish special edition: Series I Chapter 1952-1958 P. 0009 \\n English special edition: Series I Chapter 1952-1958 P. 0009 \\n Greek special edition: Chapter 08 Volume 1 P. 0005 \\n Spanish special edition: Chapter 08 Volume 1 P. 0005 \\n Portuguese special edition Chapter 08 Volume 1 P. 0005 \\n Finnish special edition: Chapter 12 Volume 3 P. 0003 \\n Swedish special edition: Chapter 12 Volume 3 P. 0003 \\nDECISION No 30-53  of 2 May 1953  on practices prohibited by Article 60 (1) of the Treaty in the common market for coal and steel\\nTHE HIGH AUTHORITY, \\nHaving regard to Article 60 and Article 63 (2) of the Treaty; \\nWhereas compliance with the obligations of non-discrimination involves uniform application by undertakings of the conditions shown in their price lists with no other increases or reductions and no evasion of those obligations by allowing longer periods for settlement without a corresponding increase in price; \\nWhereas the exception to this rule, namely the option of aligning a quotation on a competitor's price list,  must not cause that quotation to work out lower than the delivered price calculable from the conditions of the price list on which it is aligned; \\nWhereas inclusion, in the price, of taxes or charges which ultimately are not chargeable in respect of the transaction constitutes an increase as compared with the conditions applicable by the seller to a similar transaction which is in fact taxable; \\nWhereas, apart from differences related to the value or volume of procurements by the purchaser from the seller himself, the application of dissimilar conditions to comparably placed purchases is incompatible with the unity of the Community. \\nWhereas the effective operation of the common market requires that the rules of non-discrimination be applied alike to resale in an unaltered state and to sales by producers; \\nAfter consulting the Consultative Committee and the Council; \\nDECIDES:\\nArticle 1\\nThis Decision shall apply to Community undertakings in respect of their transactions within the common market in the products specified in Annex I to the Treaty, with the exception of scrap. \\n  Article 2\\n 1. It shall be a prohibited practice within the meaning of Article 60 (1) of the Treaty for a seller to apply increases or reductions on the terms calculable, for the transaction concerned, for his published price list and conditions of sale. \\n 2. This Article shall be no bar to the application of Article 60 (2) (b) of the Treaty or of Article 4 below, nor to the granting by undertakings in the coal industry of quantity or loyalty bonuses not shown in price lists pursuant to Article 2 (3) of Decision No 4-53 of 12 February 1953. \\n  Article 3\\n 1. Where a seller aligns his quotation on a competitor's price list under Article 60 (2) (b) of the Treaty, it shall be a prohibited practice within the meaning of Article 60 (1) of the Treaty for him to apply terms affording the purchaser actual delivered prices at destination lower than those calculable from the price list and conditions of sale of such competitor. \\n 2. Such delivered prices at destination shall be calculated as the sum of the price list terms plus transport costs, surcharges or taxes borne by the purchaser less rebates or drawbacks allowed him. \\n 3. This Article shall be no bar to the application in the coal industry of Decision No 3-53 of 12 February 1953, and in the steel industry of the last subparagraph of Article 60 of the Treaty and Article 30 (2) of the Convention. \\n  Article 4\\n 1. It shall be a prohibited practice within the meaning of Article 60 (1) of the Treaty for a seller to allow more favourable periods for payment than those calculable from the price list and conditions of sale on which he bases his quotation, unless offset by a corresponding increase in price. \\n 2. The increase must be in accordance with regular commercial practice as to credit in the area where the seller is established or, if the quotation is aligned on a competitor's price list, in the area where that competitor is established. \\n  Article 5\\nIt shall be a prohibited practice within the meaning of Article 60 (1) of the Treaty to include in the price charged to the purchaser the amount of any taxes or charges in respect of which the seller is entitled to exemption or drawback. \\n  Article 6\\n 1. It shall be a prohibited practice within the meaning of Article 60 (1) of the Treaty for conditions of sale to be in any way differentiated as between purchasers established within the Community according to the nationality or the location of the place of establishment of such purchasers. \\n 2. Furthermore, where conditions of sale vary according to the total volume or value of a purchaser's procurements from a number of suppliers of the product or class of products concerned over a given period, it shall be prohibited under Article 60 (1) of the Treaty for those conditions of sale to be in any way differentiated as between the suppliers from whom the purchaser has obtained his procurements within the common market, or according to the market in which he has resold. \\n 3. The foregoing paragraph shall be no bar to the differentiation of conditions of sale according to the value or volume of procurements by the purchaser from the seller himself or from a predecessor of that seller.  \\n   Article 7\\n  1. Undertakings shall frame their conditions of sale in such a way that their customers, selling agencies and commission agents, in reselling in the unaltered state other than by sale from stock in the case of steel and by retail in the case of coal, are under an obligation to comply with the rules set out in Articles 2 to 6.\\n 2. Undertakings shall be held responsible for infringements of this obligation by their direct agents, selling agencies or commission agents.\\n    Article 8\\n  This decision shall enter into force within the Community on 4 May 1953.\\n   This Decision was considered and adopted by the High Authority at its meeting on 2 May 1953.\\n  For the High Authority\\n The President\\n Jean MONNET\\n\" metadata={'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/307final.json', 'seq_num': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data storage type:\", type(data))\n",
    "print(\"Data length:\", len(data))\n",
    "print(\"Data type:\", type(data[0]))\n",
    "print(\"Data content:\", data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Move this as a function to the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 79206 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "print(f\"Split into {len(all_splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data storage type: <class 'list'>\n",
      "Data length: 79206\n",
      "Data type: <class 'langchain_core.documents.base.Document'>\n",
      "Data content: page_content='EUR-Lex - 31953D0030 - EN\\nAvis juridique important\\n|\\n31953D0030\\nECSC High Authority: Decision No 30-53 of 2 May 1953 on practices prohibited by Article 60 (1) of the Treaty in the common market for coal and steel' metadata={'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/307final.json', 'seq_num': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\"Data storage type:\", type(all_splits))\n",
    "print(\"Data length:\", len(all_splits))\n",
    "print(\"Data type:\", type(all_splits[0]))\n",
    "print(\"Data content:\", all_splits[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunking does not change the data type, just the size of the list!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever approach 1: Elastic search magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Elasticsearch.info of <Elasticsearch(['http://localhost:9200'])>>\n"
     ]
    }
   ],
   "source": [
    "es = Elasticsearch('http://localhost:9200')\n",
    "print(es.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_documents in module langchain_community.vectorstores.elasticsearch:\n",
      "\n",
      "from_documents(documents: List[langchain_core.documents.base.Document], embedding: Optional[langchain_core.embeddings.Embeddings] = None, bulk_kwargs: Optional[Dict] = None, **kwargs: Any) -> 'ElasticsearchStore' method of abc.ABCMeta instance\n",
      "    Construct ElasticsearchStore wrapper from documents.\n",
      "    \n",
      "    Example:\n",
      "        .. code-block:: python\n",
      "    \n",
      "            from langchain_community.vectorstores import ElasticsearchStore\n",
      "            from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
      "    \n",
      "            db = ElasticsearchStore.from_documents(\n",
      "                texts,\n",
      "                embeddings,\n",
      "                index_name=\"langchain-demo\",\n",
      "                es_url=\"http://localhost:9200\"\n",
      "            )\n",
      "    \n",
      "    Args:\n",
      "        texts: List of texts to add to the Elasticsearch index.\n",
      "        embedding: Embedding function to use to embed the texts.\n",
      "                  Do not provide if using a strategy\n",
      "                  that doesn't require inference.\n",
      "        metadatas: Optional list of metadatas associated with the texts.\n",
      "        index_name: Name of the Elasticsearch index to create.\n",
      "        es_url: URL of the Elasticsearch instance to connect to.\n",
      "        cloud_id: Cloud ID of the Elasticsearch instance to connect to.\n",
      "        es_user: Username to use when connecting to Elasticsearch.\n",
      "        es_password: Password to use when connecting to Elasticsearch.\n",
      "        es_api_key: API key to use when connecting to Elasticsearch.\n",
      "        es_connection: Optional pre-existing Elasticsearch connection.\n",
      "        vector_query_field: Optional. Name of the field\n",
      "                            to store the embedding vectors in.\n",
      "        query_field: Optional. Name of the field to store the texts in.\n",
      "        bulk_kwargs: Optional. Additional arguments to pass to\n",
      "                    Elasticsearch bulk.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
    "help(ElasticsearchStore.from_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27385/1555856119.py:8: DeprecationWarning: Passing transport options in the API method is deprecated. Use 'Elasticsearch.options()' instead.\n",
      "  es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n",
      "Embedding took 22.170400619506836 seconds\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "from langchain.vectorstores.elasticsearch import ElasticsearchStore\n",
    "\n",
    "REINDEX = True\n",
    "\n",
    "if REINDEX:\n",
    "    # Clear the index\n",
    "    es.indices.delete(index=\"eurlex-langchain\", ignore=[400, 404])\n",
    "\n",
    "    start_time = time.time()\n",
    "    vectorstore = ElasticsearchStore.from_documents(documents=all_splits,\n",
    "                                                    embedding=GPT4AllEmbeddings(),\n",
    "                                                    index_name=\"eurlex-langchain\",\n",
    "                                                    show_progress=True,\n",
    "                                                    es_connection=es)\n",
    "    print(f\"Embedding took {time.time() - start_time} seconds\")\n",
    "else:\n",
    "    vectorstore = ElasticsearchStore(index_name=\"eurlex-langchain\",\n",
    "                                     es_connection=es,\n",
    "                                     embedding=GPT4AllEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retriever approach 2: Langchain retriever using faiss vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_load_from_file: gguf version     = 2\n",
      "bert_load_from_file: gguf alignment   = 32\n",
      "bert_load_from_file: gguf data offset = 695552\n",
      "bert_load_from_file: model name           = BERT\n",
      "bert_load_from_file: model architecture   = bert\n",
      "bert_load_from_file: model file type      = 1\n",
      "bert_load_from_file: bert tokenizer vocab = 30522\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import GPT4AllEmbeddings\n",
    "\n",
    "embeddings = GPT4AllEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/faiss\n",
    "# https://arxiv.org/pdf/1702.08734.pdf\n",
    "# pip install faiss-cpu ; faiss-gpu didn't work for me ; Ah the reason is it is only supported for conda\n",
    "# According to the repo \"Flat\" index is the most effiecient one for small ammounts of data\n",
    "\n",
    "# Maybe we can even do better than a vectorstore: https://python.langchain.com/docs/modules/data_connection/retrievers\n",
    "from langchain_community.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method from_documents in module langchain_core.vectorstores:\n",
      "\n",
      "from_documents(documents: 'List[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' method of abc.ABCMeta instance\n",
      "    Return VectorStore initialized from documents and embeddings.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(FAISS.from_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits:  79206\n",
      "Number of batches:  1000\n",
      "Size of batches:  79\n",
      "Size of rest batch:  206\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "# The FAISS functions will not show progress, so process in batches and then merge vectorstores\n",
    "\n",
    "# make 100 batches if possible\n",
    "if (len(all_splits) >= 1000):\n",
    "    batchNum = 1000\n",
    "else:\n",
    "    batchNum = len(all_splits)\n",
    "\n",
    "# calculate the size of the batches\n",
    "size_of_batches = math.floor(len(all_splits) / batchNum)\n",
    "rest_size = len(all_splits) - (batchNum * size_of_batches)\n",
    "\n",
    "batches = [all_splits[i:i + size_of_batches] for i in range(0, batchNum * size_of_batches, size_of_batches)]\n",
    "rest_batch = all_splits[-rest_size:]\n",
    "\n",
    "print(\"Number of splits: \", len(all_splits))\n",
    "print(\"Number of batches: \", batchNum)\n",
    "print(\"Size of batches: \", size_of_batches)\n",
    "print(\"Size of rest batch: \", rest_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [08:01<00:00,  2.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# populate the vectorstores\n",
    "vectorstores = []\n",
    "for batch in tqdm(batches):\n",
    "    vectorstores.append(FAISS.from_documents(documents=batch,\n",
    "                                             embedding=embeddings))\n",
    "    \n",
    "rest_vectorstore = FAISS.from_documents(documents=rest_batch,\n",
    "                                        embedding=embeddings)\n",
    "\n",
    "# combine the vectorstores\n",
    "vectorstore = vectorstores[0]\n",
    "\n",
    "for vec in vectorstores[1:]:\n",
    "    vectorstore.merge_from(vec)\n",
    "vectorstore.merge_from(rest_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the FAISS index: 79206\n"
     ]
    }
   ],
   "source": [
    "size_of_index = vectorstore.index.ntotal\n",
    "print(\"Size of the FAISS index:\", size_of_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore type: <class 'langchain_community.vectorstores.faiss.FAISS'>\n",
      "Vectorstore content: <langchain_community.vectorstores.faiss.FAISS object at 0x7936753c7dd0>\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorstore type:\", type(vectorstore))\n",
    "print(\"Vectorstore content:\", vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use retriever like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"This is a test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 4\n",
      "Document 0\n",
      "enters the test operation.\n",
      "{'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/277final.json', 'seq_num': 1}\n",
      "\n",
      "Document 1\n",
      "shall be injected to perform the test;\n",
      "{'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/158final.json', 'seq_num': 1}\n",
      "\n",
      "Document 2\n",
      "testing method is available.\n",
      "{'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/180final.json', 'seq_num': 1}\n",
      "\n",
      "Document 3\n",
      "performance of the tests.\n",
      "{'source': '/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqm-raw/preprocessed/158final.json', 'seq_num': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(query)\n",
    "print(\"Number of docs:\", len(docs))\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i}\")\n",
    "    print(doc.page_content)\n",
    "    print(doc.metadata)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use FAISS like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =\"This is a test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs: 4\n",
      "Document 0\n",
      "enters the test operation.\n",
      "Score: 0.850996732711792\n",
      "\n",
      "Document 1\n",
      "shall be injected to perform the test;\n",
      "Score: 0.9017623662948608\n",
      "\n",
      "Document 2\n",
      "testing method is available.\n",
      "Score: 0.9205477237701416\n",
      "\n",
      "Document 3\n",
      "performance of the tests.\n",
      "Score: 0.9209227561950684\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_and_scores = vectorstore.similarity_search_with_score(query)\n",
    "\n",
    "print(\"Number of docs:\", len(docs_and_scores))\n",
    "for i, (doc, score) in enumerate(docs_and_scores):\n",
    "    print(f\"Document {i}\")\n",
    "    print(doc.page_content)\n",
    "    print(f\"Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query embedding length: 384\n",
      "Query embedding: [0.02008598856627941, 0.020369146019220352, -0.03328794240951538, 0.05006341636180878, 0.010319828987121582, -0.03074713610112667, -0.006307267118245363, 0.020657578483223915, -0.0006196335889399052, 0.01820748671889305, 0.03446296229958534, -0.08538782596588135, 0.007782005239278078, 0.04672839492559433, -0.051374878734350204, -0.051072221249341965, 0.020909084007143974, -0.05579216033220291, -0.059465520083904266, 0.05841923505067825, 0.04251153767108917, 0.017066456377506256, -0.05490635335445404, 0.018923688679933548, 0.03195365145802498, -0.004465232603251934, -0.0431266613304615, 0.011368070729076862, 0.03462895005941391, -0.035111717879772186, 0.012774482369422913, 0.03956768661737442, 0.05025430768728256, 0.018407776951789856, 0.06511792540550232, -0.01580517180263996, 0.03316093981266022, 0.017037540674209595, 0.03508692607283592, 0.029834900051355362, 0.014514746144413948, -0.10974641144275665, 0.043374933302402496, 0.02615693397819996, -0.003301292657852173, 0.0791264995932579, -0.04759564995765686, 0.031187739223241806, -0.03561436012387276, -0.006660789716988802, 0.004182141739875078, -0.0031587027478963137, -0.11275702714920044, -0.05134901404380798, 0.036049190908670425, -0.007869078777730465, -0.00410698726773262, -0.03277330473065376, 0.025469550862908363, 0.05354490876197815, 0.014800010249018669, -0.0253036767244339, -0.02935544028878212, 0.0434565506875515, 0.09834370762109756, 0.0055596730671823025, -0.03389619663357735, -0.09110429883003235, 0.013286841101944447, -0.08824211359024048, 0.002652454189956188, 0.013986843638122082, 0.06671274453401566, 0.007041485048830509, 0.03689140826463699, 0.006420061457902193, -0.03857345134019852, -0.10538045316934586, 0.041725266724824905, 0.024260560050606728, -0.06901994347572327, -0.07575538009405136, -0.011991839855909348, 0.029459988698363304, 0.012281501665711403, 0.07538206875324249, 0.08733280748128891, 0.020435646176338196, -0.07119709998369217, 0.009843822568655014, -0.002842274960130453, 0.04440856724977493, -0.06374366581439972, -0.013044421561062336, -0.023165106773376465, -0.000458345515653491, -0.022162340581417084, -0.03278999403119087, -0.005379106849431992, 0.17283375561237335, -0.0009256966295652092, 0.0023225757759064436, -0.019756527617573738, -0.01924900896847248, -0.07595939189195633, -0.05226150155067444, 0.08212705701589584, -0.03308594226837158, 0.03116501308977604, 0.014100123196840286, -0.02724646031856537, -0.02116590179502964, 0.017536794766783714, 0.03285237401723862, 0.012120719999074936, -0.058188483119010925, -0.1540919691324234, 0.05743096023797989, -0.028936661779880524, 0.04265839233994484, 0.1169150173664093, -0.007261470891535282, -0.010373924858868122, -0.022644199430942535, -0.02282809279859066, -0.013446219265460968, 0.021006964147090912, -7.181245599387053e-33, -0.004713017959147692, -0.049790095537900925, 0.04281407222151756, 0.06135028600692749, -0.01711983047425747, 0.010894584469497204, -0.054185375571250916, 0.051847465336322784, -0.015280341729521751, -0.0108334980905056, -0.02279438078403473, -0.09333310276269913, 0.025049159303307533, 0.01236581802368164, 0.036955010145902634, 0.08181462436914444, -0.03843097761273384, 0.09202605485916138, -0.08153268694877625, 0.02954593300819397, -0.02663397416472435, 0.003532378003001213, 0.0022507847752422094, -0.10229219496250153, -0.06466333568096161, -0.06560299545526505, -0.04036983102560043, 0.008328096941113472, -0.01565464586019516, 0.016608236357569695, 0.004804064054042101, 0.03594449162483215, -0.09146835654973984, 0.07637792080640793, -0.011342584155499935, -0.014355810359120369, 0.023114513605833054, 0.01912403292953968, 0.00942973792552948, 0.020319676026701927, -0.05787095054984093, -0.05351435765624046, 0.0064507112838327885, 0.04064006730914116, 0.0499560572206974, -0.05805198848247528, -0.020107600837945938, -0.04683772847056389, 0.07271193712949753, 0.03168705105781555, -0.012603390961885452, 0.02590338885784149, -0.021214714273810387, -0.002142355777323246, -0.016096577048301697, 0.07653404027223587, 0.04600827768445015, 0.02720291167497635, -0.040545374155044556, 0.08740804344415665, 0.014126313850283623, 0.02845509722828865, -0.08926022797822952, 0.05484175682067871, -0.034354183822870255, 0.023028777912259102, -0.06784316897392273, -0.07186222076416016, 0.060501646250486374, 0.06089780107140541, 0.033560480922460556, -0.027775220572948456, 0.04214915260672569, 0.05999433621764183, -0.012100499123334885, -0.05741352215409279, -0.010127240791916847, 0.10996939986944199, -0.04585163667798042, -0.03296831250190735, 0.0016898371977731586, -0.08800406008958817, 0.015199710614979267, -0.07529124617576599, -0.05874302610754967, -0.015909163281321526, -0.038616396486759186, -0.04584942385554314, -0.006532247643917799, -0.03609718754887581, -0.04640764370560646, 0.006442531477659941, -0.043843742460012436, -0.06048969179391861, 0.09065697342157364, 3.0524273029443503e-33, -0.07682285457849503, 0.14084260165691376, -0.03993254899978638, 0.09489551186561584, 0.062354471534490585, 0.006226242054253817, 0.1246497854590416, -0.03525903448462486, -0.07306915521621704, 0.1479947865009308, 0.027072593569755554, 0.020268434658646584, 0.014083297923207283, -0.015565182082355022, 0.03221825137734413, 0.038402918726205826, 0.024930987507104874, -0.05492907762527466, -0.015048409812152386, -0.05141640082001686, -0.041951827704906464, 0.16588547825813293, 0.06617904454469681, 0.05517297610640526, -0.06428145617246628, 0.03491035848855972, -0.006587590090930462, -0.06753835082054138, -0.008429016917943954, -0.005052424967288971, -0.0071466825902462006, 0.005520832724869251, -0.0019153407774865627, 0.05095723271369934, 0.021317554637789726, -0.03605250269174576, 0.13265405595302582, -0.018129270523786545, -0.051031216979026794, 0.04696787893772125, 0.035290587693452835, 0.08779781311750412, 0.06567103415727615, 0.051579397171735764, -0.0157907884567976, 0.039477430284023285, 0.04317620396614075, -0.07516758888959885, 0.03156570717692375, 0.0732317715883255, -0.06246461719274521, -0.029476413503289223, 0.01950228027999401, 0.06573861837387085, -0.03362961858510971, 0.05915412679314613, -0.07103390246629715, 0.03540683910250664, -0.009551748633384705, 0.041193507611751556, -0.06174452230334282, 0.07794663310050964, -0.030223770067095757, 0.00918978825211525, 0.003306681988760829, -0.033812910318374634, -0.07404404133558273, 0.004438706208020449, 0.04405010864138603, 0.006782754324376583, 0.05037393793463707, 0.02354476787149906, -0.0852077454328537, -0.08915870636701584, 0.0377313457429409, -0.09197621047496796, -0.04619838669896126, -0.03144201263785362, 0.014361804351210594, -0.049070216715335846, -0.05816352739930153, -0.06913258880376816, -0.035724520683288574, 0.02837403677403927, -0.0640428215265274, 0.06159800663590431, -0.017502453178167343, 0.0644959881901741, -0.024142136797308922, 0.03705630451440811, 0.03160199522972107, 0.005849948152899742, 0.008975844830274582, -0.08201737701892853, 0.007128103636205196, -2.0171828651882606e-08, -0.002347194356843829, -0.09199907630681992, -0.03807478025555611, 0.007362358272075653, -0.021839860826730728, 0.03658882901072502, 0.022857647389173508, -0.07279851287603378, -0.030091170221567154, -0.047762930393218994, 0.06797066330909729, 0.0364978164434433, -0.04202311486005783, 0.04257962480187416, 0.04532323405146599, -0.11487920582294464, 0.0012223842786625028, -0.002370122354477644, -0.019641166552901268, 0.028365666046738625, -0.0665111094713211, 0.008847507648169994, 0.034531667828559875, 0.04070984944701195, -0.04857592284679413, 0.05672091618180275, -0.001150553347542882, 0.06260468065738678, 0.0022447844967246056, -0.012191878631711006, 0.08207487314939499, 0.0915757417678833, -0.040213584899902344, -0.055263862013816833, -0.0098516084253788, 0.06692221760749817, 0.03896788880228996, 0.011693816632032394, 0.009397793561220169, 0.06099017336964607, -0.15774281322956085, -0.027958976104855537, 0.006640897132456303, 0.05557405576109886, -0.039213281124830246, -0.06266035884618759, -0.07037511467933655, 0.015355812385678291, -0.032680027186870575, -0.07978900521993637, -0.02703656256198883, -0.006669154856353998, 0.03536641225218773, -0.016391457989811897, -0.003786714281886816, -0.02215096727013588, -0.039109259843826294, -0.006356175523251295, -0.07298506796360016, 0.031270626932382584, 0.09739252924919128, 0.012022305279970169, 0.10179422795772552, -0.018850965425372124]\n",
      "Number of docs: 4\n",
      "Document 0\n",
      "enters the test operation.\n",
      "\n",
      "Document 1\n",
      "shall be injected to perform the test;\n",
      "\n",
      "Document 2\n",
      "testing method is available.\n",
      "\n",
      "Document 3\n",
      "performance of the tests.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_vector = embeddings.embed_query(query)\n",
    "print(\"Query embedding length:\", len(embedding_vector))\n",
    "print(\"Query embedding:\", embedding_vector)\n",
    "\n",
    "docs = vectorstore.similarity_search_by_vector(embedding_vector)\n",
    "\n",
    "print(\"Number of docs:\", len(docs))\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"Document {i}\")\n",
    "    print(doc.page_content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"faiss_index\"\n",
    "dir = \"./\"\n",
    "path = os.path.join(dir, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving file to:  ./faiss_index\n"
     ]
    }
   ],
   "source": [
    "# Saving the vectorstore\n",
    "print(\"Saving file to: \", path)\n",
    "vectorstore.save_local(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the vectorstore\n",
    "vectorstore = FAISS.load_local(path, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: You can search the vectorstore by filtering their metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build another chain and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=5, memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt},\n",
    "    memory=memory,\n",
    "    get_chat_history=lambda h : h,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is your job?\"\n",
    "history = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'What is your job?', 'chat_history': '', 'answer': 'As ELQM, my job is to assist in answering question-answering tasks related to energy law, using the context provided by EU regulations and other legal documents. My expertise lies in providing information on employment, operation, and maintenance of energy-related systems, as well as the fulfillment of duties within the domain of energy law. I am here to help you navigate these complex legal issues and provide accurate answers to your questions. How may I assist you today?'}\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"question\": question, \"chat_history\": history})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream output word for word vs output whole answer at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streamed\n",
    "# Did not work\n",
    "for chunk in qa_chain.stream({\"question\": question, \"chat_history\": history}):\n",
    "    print(chunk, end=\"\", flush=True)\n",
    "\n",
    "# I don't know how to write a function that streams to gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole\n",
    "def answer_question(question, history):\n",
    "    result = qa_chain({\"question\": question, \"chat_history\": history})\n",
    "    return result['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/home/computerman/Desktop/NLPT/elqm-INLPT-WS2023/elqmVenv/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:189: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "css = \"\"\"#chatbot {height: 100%;}\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css) as demo:\n",
    "   gr.ChatInterface(fn=answer_question, title=\"ELQM\")\n",
    "\n",
    "demo.launch();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elqmVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
