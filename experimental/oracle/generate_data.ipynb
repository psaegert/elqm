{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, JSONLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from elqm.utils.dataFinder import get_data_dir\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/psaegert/Projects/elqm-INLPT-WS2023/elqm-raw/eur_lex_data\n",
      "/home/psaegert/Projects/elqm-INLPT-WS2023/elqm-raw/preprocessed\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = get_data_dir(\"eur_lex_data\")\n",
    "PREPROCESSED_DATA_DIR = get_data_dir(\"preprocessed\")\n",
    "\n",
    "print(os.path.abspath(DATA_DIR))\n",
    "print(os.path.abspath(PREPROCESSED_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:08<00:00, 59.69it/s] \n"
     ]
    }
   ],
   "source": [
    "for filename in tqdm(os.listdir(DATA_DIR)):\n",
    "    if filename.endswith(\".json\"):\n",
    "        with open(os.path.join(DATA_DIR, filename), 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        bs = BeautifulSoup(data['html'], 'html.parser')\n",
    "\n",
    "        # Get the text\n",
    "        text = bs.get_text()\n",
    "\n",
    "        data['text'] = text\n",
    "        del data['html']\n",
    "\n",
    "        with open(os.path.join(PREPROCESSED_DATA_DIR, filename), 'w') as f:\n",
    "            json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    'jq_schema': '.text'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:00<00:00, 720.84it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(PREPROCESSED_DATA_DIR, glob='**/*.json', show_progress=True, loader_cls=JSONLoader, loader_kwargs=schema)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 5832 chunks\n"
     ]
    }
   ],
   "source": [
    "# Split into chunks \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "print(f\"Split into {len(all_splits)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elqm.eval.oracle import QUSTION_TYPES, generate_question_answer_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['confirmation',\n",
       " 'factoid',\n",
       " 'list',\n",
       " 'causal',\n",
       " 'hypothetical',\n",
       " 'complex',\n",
       " 'default']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(QUSTION_TYPES.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/psaegert/Projects/elqm-INLPT-WS2023/elqm-raw/question_answer_pairs\n"
     ]
    }
   ],
   "source": [
    "N_DOCUMENTS = 100\n",
    "N_QUESTIONS = 5\n",
    "\n",
    "DATA_DIR = get_data_dir(\"question_answer_pairs\")\n",
    "print(os.path.abspath(DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 20240102\n",
    "\n",
    "# Choose random splits\n",
    "np.random.seed(random_state)\n",
    "random_splits = np.random.choice(all_splits, N_DOCUMENTS, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to a source_name.csv that contains columns source, type, question, answer in append mode\n",
    "# If the file does not exist, create it and write the header\n",
    "filename = os.path.join(DATA_DIR, f\"random_{N_DOCUMENTS}_{random_state}.csv\")\n",
    "\n",
    "if not os.path.exists(filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"source\", \"type\", \"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [40:30<00:00, 24.30s/it]\n"
     ]
    }
   ],
   "source": [
    "for split in tqdm(random_splits):\n",
    "    for question_type in QUSTION_TYPES.keys():\n",
    "        qa_pairs = generate_question_answer_pairs(\n",
    "            context=split.page_content,\n",
    "            prompt=None,\n",
    "            question_type=question_type,\n",
    "            n=N_QUESTIONS)\n",
    "\n",
    "        with open(filename, 'a', newline='') as f:\n",
    "            writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "            for qa_pair in qa_pairs:\n",
    "                writer.writerow([os.path.splitext(os.path.basename(split.metadata['source']))[0], question_type, qa_pair[0], qa_pair[1]])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elqm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
